{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreading in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synchronous: Actions that happen one after another. Programming as we've seen it until now is synchronous, because each line executes after the previous one.\n",
    "#### Asynchronous: Actions that don't necessary happen after one another, or that can happen in arbitrary order (\"without synchrony\").\n",
    "#### Concurrency: The ability of our programs to run things in different order every time the program runs, without affecting the final outcome.\n",
    "#### Parallelism: Running two or more things at the same time.\n",
    "#### Thread: A line of code execution that can run in one of your computer's cores.\n",
    "#### Process: One of more threads and the resources they need (e.g. network connection, mouse pointer, hard drive access, or even the core(s) in which the thread(s) run).\n",
    "#### GIL: A key, critical, important resource in any Python program. Only one is created per Python process, so it's unique in each.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "print(threading.current_thread().getName())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the main thread name as appropriate\n",
    "threading.current_thread().name = \"primary\"\n",
    "print(threading.current_thread().getName())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ways of creating threads...usually 3\n",
    "#### Extending the thread class\n",
    "#### Using the function\n",
    "#### Without extending the thread class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the function\n",
    "\n",
    "import threading\n",
    "from time import sleep\n",
    "\n",
    "def Car():\n",
    "    for i in range(5):\n",
    "        print(\"car\")\n",
    "        sleep(1)\n",
    "\n",
    "def Truck():\n",
    "    for i in range(5):\n",
    "        print(\"truck\")\n",
    "        sleep(1)\n",
    "\n",
    "\n",
    "print(threading.current_thread().name)\n",
    "t1= threading.Thread(target=Car)\n",
    "t2= threading.Thread(target=Truck)\n",
    "t1.start()\n",
    "#sleep(0.5)\n",
    "t2.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extending the thread class\n",
    "\n",
    "from threading import *\n",
    "import threading\n",
    "from time import sleep\n",
    "\n",
    "class Car(Thread):\n",
    "    def run(self):\n",
    "        for i in range(5):\n",
    "            print(\"car\")\n",
    "            sleep(0.3)\n",
    "            \n",
    "class Truck(Thread):\n",
    "    def run(self):\n",
    "        for i in range(5):\n",
    "            print(\"truck\")\n",
    "            sleep(0.3)\n",
    "\n",
    "t1 = Car()\n",
    "t2 = Truck()\n",
    "print(threading.current_thread().name)\n",
    "t1.start()\n",
    "sleep(0.2)\n",
    "t2.start()\n",
    "\n",
    "print('done')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without extending the thread class\n",
    "from threading import *\n",
    "import threading\n",
    "from time import sleep\n",
    "\n",
    "class Car():\n",
    "    def A(self):\n",
    "        for i in range(5):\n",
    "            print(\"car\")\n",
    "            sleep(0.3)\n",
    "            \n",
    "class Truck():\n",
    "    def B(self):\n",
    "        for i in range(5):\n",
    "            print(\"truck\")\n",
    "            sleep(0.3)\n",
    "\n",
    "t1 = Car()\n",
    "t2 = Truck()\n",
    "print(threading.current_thread().name)\n",
    "\n",
    "t1= threading.Thread(target=t1.A)\n",
    "t2= threading.Thread(target=t2.B)\n",
    "\n",
    "t1.start()\n",
    "sleep(0.2)\n",
    "t2.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name a thread\n",
    "#Using the function\n",
    "\n",
    "import threading\n",
    "from time import sleep\n",
    "\n",
    "def Car():\n",
    "    for i in range(5):\n",
    "        print(threading.current_thread().name)\n",
    "        print('in car function')\n",
    "        sleep(1)\n",
    "\n",
    "def Truck():\n",
    "    for i in range(5):\n",
    "        print(threading.current_thread().name)\n",
    "        print('in truck function')\n",
    "        sleep(1)\n",
    "\n",
    "\n",
    "print(threading.current_thread().name)\n",
    "t1= threading.Thread(name='SecondThread', target=Car)\n",
    "t2= threading.Thread(name='ThirdThread', target=Truck)\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "a = []\n",
    "b = a\n",
    "sys.getrefcount(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GIL: Global Interepreter Lock\n",
    "The Python Global Interpreter Lock or GIL, in simple words, is a mutex (or a lock) that allows only one thread to hold the control of the Python interpreter.\n",
    "\n",
    "This means that only one thread can be in a state of execution at any point in time. The impact of the GIL isn’t visible to developers who execute single-threaded programs, but it can be a performance bottleneck in CPU-bound and multi-threaded code.\n",
    "\n",
    "Since the GIL allows only one thread to execute at a time even in a multi-threaded architecture with more than one CPU core, the GIL has gained a reputation as an “infamous” feature of Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The impact on multi-threaded Python programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you look at a typical Python program—or any computer program for that matter—there’s a difference between those that are CPU-bound in their performance and those that are I/O-bound.\n",
    "\n",
    "CPU-bound programs are those that are pushing the CPU to its limit. This includes programs that do mathematical computations like matrix multiplications, searching, image processing, etc.\n",
    "\n",
    "I/O-bound programs are the ones that spend time waiting for Input/Output which can come from a user, file, database, network, etc. I/O-bound programs sometimes have to wait for a significant amount of time till they get what they need from the source due to the fact that the source may need to do its own processing before the input/output is ready, for example, a user thinking about what to enter into an input prompt or a database query running in its own process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multithreading Vs Multiprocessing\n",
    "\n",
    "#### Multithreading:\n",
    "- A new thread is spawned within the existing process\n",
    "- Starting a thread is faster than starting a process\n",
    "- Memory is shared between all threads\n",
    "- One GIL(Global Interpreter Lock) for all threads\n",
    "\n",
    "#### Multiprocessing:\n",
    "- A new process is started independent from the first process\n",
    "- Starting a process is slower than starting a thread\n",
    "- Memory is not shared between processes\n",
    "- One GIL(Global Interpreter Lock) for each process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of cores\n",
    "import os\n",
    "print(os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multithreading:\n",
    "import os, math\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def calc():\n",
    "    for i in range(0,40000000):\n",
    "        math.sqrt(i)\n",
    "\n",
    "threads = []\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "for i in range(os.cpu_count()):\n",
    "    print('registering thread %d' %i)\n",
    "    threads.append(threading.Thread(target=calc))\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(end-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiprocessing:\n",
    "import os, math\n",
    "from multiprocessing import Process\n",
    "import time\n",
    "\n",
    "\n",
    "def calc():\n",
    "    for i in range(0,40000000):\n",
    "        math.sqrt(i)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processes = []\n",
    "    st = time.time()\n",
    "\n",
    "    for i in range(os.cpu_count()):\n",
    "        print('registering process %d' %i)\n",
    "        processes.append(Process(target=calc))\n",
    "\n",
    "    for process in processes:\n",
    "        process.start()\n",
    "\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "    end = time.time()\n",
    "    print(end-st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What should you use?\n",
    "If your code has a lot of I/O or Network usage:\n",
    " - Multithreading is your best bet because of its low overhead\n",
    "\n",
    "If your code is CPU bound:\n",
    "- You should use multiprocessing (if your machine has multiple cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few references:\n",
    "https://realpython.com/python-gil/\n",
    "\n",
    "https://timber.io/blog/multiprocessing-vs-multithreading-in-python-what-you-need-to-know/\n",
    "\n",
    "https://www.beautifulcode.co/blog/81-global-interpreter-lock-gil-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
